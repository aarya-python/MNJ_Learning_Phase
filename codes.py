# -*- coding: utf-8 -*-
"""codes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BZB5t6rA_gzGbvY8l_wAos9Xc7-8Huko
"""

#D1  Python Basics
x = 5
y = 10
print("Sum:", x + y)

def greet(name):
    return f"Hello, {name}"

print(greet("Alice"))

# NumPy Basics
import numpy as np

a = np.array([1, 2, 3])
b = np.array([4, 5, 6])

print("Element-wise addition:", a + b)
print("Mean of a:", np.mean(a))
print("Reshaped:", a.reshape(3, 1))

#Day 2
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load dataset (replace path with uploaded titanic.csv)
url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'
df = pd.read_csv(url)
df.head()

# Basic info
print(df.info())
print(df.describe())

# Handle nulls
df['Age'].fillna(df['Age'].median(), inplace=True)
df.dropna(subset=['Embarked'], inplace=True)

# Grouping
print(df.groupby('Pclass')['Survived'].mean())

# EDA
sns.countplot(x='Survived', data=df)
plt.title("Survival Count")
plt.show()

#Day 3
# Matplotlib & Seaborn
sns.histplot(df['Age'].dropna(), kde=True)
plt.title("Age Distribution")
plt.show()

sns.boxplot(x='Pclass', y='Age', data=df)
plt.title("Age vs Class")
plt.show()

# Simulate Normal & Binomial
normal_data = np.random.normal(50, 10, 1000)
sns.histplot(normal_data, kde=True)
plt.title("Simulated Normal Distribution")
plt.show()

binom_data = np.random.binomial(n=10, p=0.5, size=1000)
sns.histplot(binom_data, bins=10)
plt.title("Simulated Binomial Distribution")
plt.show()

#Day 4
#SQLite
import sqlite3

conn = sqlite3.connect(':memory:')
cur = conn.cursor()

cur.execute("CREATE TABLE people (name TEXT, age INTEGER);")
cur.executemany("INSERT INTO people VALUES (?, ?)", [('Alice', 25), ('Bob', 30), ('Charlie', 35)])
conn.commit()

df_sql = pd.read_sql("SELECT * FROM people", conn)
print(df_sql)

# Hypothesis Testing
from scipy.stats import ttest_ind

group1 = np.random.normal(70, 10, 50)
group2 = np.random.normal(75, 10, 50)

t_stat, p_val = ttest_ind(group1, group2)
print("T-statistic:", t_stat)
print("P-value:", p_val)

#Day 5
from sklearn.datasets import make_blobs
from sklearn.cluster import KMeans, DBSCAN
from sklearn.decomposition import PCA

# sample data generatng
X, _ = make_blobs(n_samples=300, centers=4, cluster_std=0.6)

# KMeans
kmeans = KMeans(n_clusters=4)
labels_kmeans = kmeans.fit_predict(X)

# DBSCAN
db = DBSCAN(eps=0.9)
labels_dbscan = db.fit_predict(X)

#principal component analysis
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

# Visualize
sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=labels_kmeans)
plt.title("KMeans Clustering with PCA")
plt.show()

#Day 6
# A/B Testing
group_a = np.random.normal(30, 5, 100)
group_b = np.random.normal(32, 5, 100)

t_stat, p_val = ttest_ind(group_a, group_b)
print("T-stat:", t_stat)
print("P-value:", p_val)

# Time Series Forecasting
date_range = pd.date_range(start='2023-01-01', periods=100)
ts = pd.Series(np.random.randn(100).cumsum(), index=date_range)

ts.plot(title="Simulated Time Series")
plt.show()

#d7
#Data Storytelling
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'
df = pd.read_csv(url)

#  missing values
df['Age'].fillna(df['Age'].median(), inplace=True)
df.dropna(subset=['Embarked'], inplace=True)

# Story 1: Survival rate by gender
sns.barplot(x='Sex', y='Survived', data=df)
plt.title('Survival Rate by Gender')
plt.ylabel('Survival Rate')
plt.xlabel('Gender')
plt.show()

# Story 2: Survival by passenger class
sns.barplot(x='Pclass', y='Survived', data=df)
plt.title('Survival Rate by Passenger Class')
plt.ylabel('Survival Rate')
plt.xlabel('Passenger Class')
plt.show()

# Story 3: Age distribution
sns.histplot(data=df, x='Age', hue='Survived', multiple='stack', kde=True)
plt.title('Age Distribution by Survival Status')
plt.show()

#Day 8 mini project was done. a seperate file has been attached for it

#Day 9 : Data Wrangling and Cleaning
import pandas as pd
import numpy as np

# Sample datasets
df1 = pd.DataFrame({
    'ID': [1, 2, 3, 4],
    'Name': ['Alice', 'Bob', np.nan, 'David'],
    'Age': [25, np.nan, 29, 40]
})

df2 = pd.DataFrame({
    'ID': [3, 4, 5],
    'City': ['Delhi', 'Mumbai', 'Bangalore']
})

print("DF1:\n", df1)
print("\nDF2:\n", df2)

# Fill missing with a specific value or method
df1['Age'].fillna(df1['Age'].mean(), inplace=True)
df1['Name'].fillna('Unknown', inplace=True)

# Drop rows with missing data (if needed)
df_cleaned = df1.dropna()

print("After filling missing data:\n", df1)

# Inner join on 'ID'
merged_df = pd.merge(df1, df2, on='ID', how='inner')
print("Merged (Inner Join):\n", merged_df)

# Outer join (all records from both)
merged_outer = pd.merge(df1, df2, on='ID', how='outer')
print("Merged (Outer Join):\n", merged_outer)

df_part1 = df1.iloc[:2]
df_part2 = df1.iloc[2:]

# Concatenate row-wise
concat_df = pd.concat([df_part1, df_part2], axis=0)
print("Concatenated DataFrame:\n", concat_df)

# Create pivot table (example)
df_pivot = pd.DataFrame({
    'ID': [1, 2, 1, 2],
    'Year': [2022, 2022, 2023, 2023],
    'Sales': [100, 150, 110, 180]
})

pivoted = df_pivot.pivot(index='ID', columns='Year', values='Sales')
print("Pivoted Table:\n", pivoted)

# Melt (reverse of pivot)
melted = pd.melt(pivoted.reset_index(), id_vars='ID', value_name='Sales')
print("Melted Data:\n", melted)

df_text = pd.DataFrame({
    'Email': ['ALICE@example.com', ' bob@example.com ', 'DAVID123@MAIL.COM', 'invalid@@.com']
})

# Convert to lowercase and strip whitespace
df_text['Email'] = df_text['Email'].str.lower().str.strip()

# Remove anything thatâ€™s not alphanumeric/@/dot using regex
df_text['Email'] = df_text['Email'].str.replace(r'[^a-z0-9@._]', '', regex=True)

print("Cleaned Emails:\n", df_text)

#Day 10 sql